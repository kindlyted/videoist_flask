# æ–°å¢åŠ äº†opencv/ffé™é»˜è¾“å‡º/åˆ¤æ®µæ˜¯å¦æœ‰comfyui
# ===== Pythonæ ‡å‡†åº“ =====
import os
import io
import asyncio
import re
import base64
import time
import subprocess
import shutil
from typing import Dict, List, Tuple
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from flask import current_app
from config import Config
# ===== å›¾åƒ/è§†é¢‘å¤„ç† =====
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
# ===== éŸ³é¢‘å¤„ç† =====
from pydub import AudioSegment
# ===== å­—å¹•å¤„ç† =====
import pysrt
# ===== ç½‘ç»œè¯·æ±‚ =====
import requests
from .cookielogin import CookieLogin
# ===== æ•°æ®è§£æ =====
import yaml
import markdown
from bs4 import BeautifulSoup
# ===== æ¨¡æ¿å¼•æ“ =====
from jinja2 import Template
# ===== è¯­éŸ³åˆæˆ =====
import edge_tts
# ===== æµè§ˆå™¨è‡ªåŠ¨åŒ– =====
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
# ===== AIæœåŠ¡ =====
from openai import OpenAI

async def speaking(OUTPUT_FILE: str, WEBVTT_FILE: str, TEXT: str, VOICE: str) -> None:
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    os.makedirs(os.path.dirname(WEBVTT_FILE), exist_ok=True)
    
    communicate = edge_tts.Communicate(TEXT, VOICE)
    submaker = edge_tts.SubMaker()
    with open(OUTPUT_FILE, "wb") as file:
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                file.write(chunk["data"])
            elif chunk["type"] == "WordBoundary":
                submaker.feed(chunk)

    with open(WEBVTT_FILE, "w", encoding="utf-8") as file:
        file.write(submaker.get_srt())

async def process_dialogue(
    input_file: str,
    output_audio: str,
    output_srt: str,
    voice_mapping: Dict[str, str],
    temp_dir: str = "tmp",
    silence_duration_ms: int = 500
) -> None:
    """
    å¤„ç†å¤šè§’è‰²å¯¹è¯æ–‡æœ¬ï¼Œç”Ÿæˆåˆå¹¶åçš„éŸ³é¢‘å’Œå­—å¹•ï¼ˆå¸¦é™éŸ³é—´éš”ï¼‰
    
    Args:
        input_file: è¾“å…¥æ–‡æœ¬æ–‡ä»¶è·¯å¾„
        output_audio: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        output_srt: è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„
        voice_mapping: è§’è‰²åˆ°è¯­éŸ³çš„æ˜ å°„å­—å…¸
        temp_dir: ä¸´æ—¶æ–‡ä»¶å­˜æ”¾ç›®å½•
        silence_duration_ms: è§’è‰²é—´é™éŸ³é—´éš”æ—¶é•¿(æ¯«ç§’)
    """
    # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
    os.makedirs(temp_dir, exist_ok=True)
    
    # è§£æå¯¹è¯æ–‡æœ¬
    dialogues = parse_dialogue_file(input_file, voice_mapping)
    
    # ä¸ºæ¯ä¸ªå¯¹è¯ç‰‡æ®µç”ŸæˆéŸ³é¢‘å’Œå­—å¹•
    tasks = []
    for i, (speaker, text) in enumerate(dialogues):
        voice = voice_mapping.get(speaker)
        if not voice:
            continue
            
        audio_file = os.path.join(temp_dir, f"part_{i}.mp3")
        srt_file = os.path.join(temp_dir, f"part_{i}.srt")
        
        tasks.append(speaking(audio_file, srt_file, text, voice))
    
    # å¹¶è¡Œå¤„ç†æ‰€æœ‰å¯¹è¯ç‰‡æ®µ
    await asyncio.gather(*tasks)
    
    # åˆå¹¶éŸ³é¢‘å’Œå­—å¹•ï¼ˆå¸¦é™éŸ³é—´éš”ï¼‰
    merge_audio_and_srt_with_silence(
        temp_dir, 
        len(dialogues), 
        output_audio, 
        output_srt,
        silence_duration_ms
    )
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    for i in range(len(dialogues)):
        try:
            os.remove(os.path.join(temp_dir, f"part_{i}.mp3"))
            os.remove(os.path.join(temp_dir, f"part_{i}.srt"))
        except:
            pass

def parse_dialogue_file(
    file_path: str, 
    voice_mapping: Dict[str, str]
) -> List[Tuple[str, str]]:
    """
    è§£æå¯¹è¯æ–‡æœ¬æ–‡ä»¶ï¼Œè¿”å›(è§’è‰², æ–‡æœ¬)åˆ—è¡¨
    
    è¾“å…¥æ–‡ä»¶æ ¼å¼ç¤ºä¾‹:
    momo: ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”çœŸå¥½
    labubu: æ˜¯å•Šï¼Œé€‚åˆå‡ºå»ç©
    
    Args:
        file_path: æ–‡æœ¬æ–‡ä»¶è·¯å¾„
        voice_mapping: è§’è‰²åˆ°è¯­éŸ³çš„æ˜ å°„å­—å…¸
        
    Returns:
        åŒ…å«(è§’è‰², æ–‡æœ¬)å…ƒç»„çš„åˆ—è¡¨
    """
    dialogues = []
    current_speaker = None
    current_text = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
                
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„è¯´è¯è€…è¡Œ
            parts = line.split(':', 1)
            if len(parts) == 2 and parts[0] in voice_mapping:
                # ä¿å­˜å‰ä¸€ä¸ªè¯´è¯è€…çš„å†…å®¹
                if current_speaker and current_text:
                    dialogues.append((current_speaker, ' '.join(current_text)))
                    current_text = []
                
                current_speaker = parts[0]
                current_text.append(parts[1].strip())
            else:
                # ç»§ç»­å½“å‰è¯´è¯è€…çš„å†…å®¹
                current_text.append(line)
    
    # æ·»åŠ æœ€åä¸€ä¸ªè¯´è¯è€…çš„å†…å®¹
    if current_speaker and current_text:
        dialogues.append((current_speaker, ' '.join(current_text)))
    
    return dialogues

def merge_audio_and_srt_with_silence(
    temp_dir: str, 
    part_count: int,
    output_audio: str,
    output_srt: str,
    silence_duration_ms: int = 500
) -> None:
    """
    åˆå¹¶å¤šä¸ªéŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶ï¼Œåœ¨éŸ³é¢‘é—´æ·»åŠ é™éŸ³é—´éš”
    
    Args:
        temp_dir: ä¸´æ—¶æ–‡ä»¶ç›®å½•
        part_count: éƒ¨åˆ†æ–‡ä»¶æ•°é‡
        output_audio: è¾“å‡ºéŸ³é¢‘è·¯å¾„
        output_srt: è¾“å‡ºå­—å¹•è·¯å¾„
        silence_duration_ms: é™éŸ³é—´éš”æ—¶é•¿(æ¯«ç§’)
    """
    # åˆå¹¶éŸ³é¢‘ï¼ˆå¸¦é™éŸ³é—´éš”ï¼‰
    silence = AudioSegment.silent(duration=silence_duration_ms)
    combined_audio = None
    first_audio = True
    
    for i in range(part_count):
        audio_file = os.path.join(temp_dir, f"part_{i}.mp3")
        
        if not os.path.exists(audio_file):
            continue
            
        audio = AudioSegment.from_mp3(audio_file)
        
        if combined_audio is None:
            combined_audio = audio
            first_audio = False
        else:
            combined_audio += silence + audio
    
    if combined_audio is not None:
        combined_audio.export(output_audio, format="mp3")
    
    # åˆå¹¶å­—å¹•å¹¶è°ƒæ•´æ—¶é—´æˆ³ï¼ˆè€ƒè™‘é™éŸ³é—´éš”ï¼‰
    with open(output_srt, 'w', encoding='utf-8') as out_srt:
        total_duration = 0  # æ¯«ç§’
        first_audio = True  # æ ‡è®°æ˜¯å¦æ˜¯ç¬¬ä¸€ä¸ªéŸ³é¢‘
        
        for i in range(part_count):
            audio_file = os.path.join(temp_dir, f"part_{i}.mp3")
            srt_file = os.path.join(temp_dir, f"part_{i}.srt")
            
            if not os.path.exists(audio_file) or not os.path.exists(srt_file):
                continue
                
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªéŸ³é¢‘ï¼Œæ·»åŠ é™éŸ³é—´éš”æ—¶é—´
            if not first_audio:
                total_duration += silence_duration_ms
            else:
                first_audio = False
                
            # è¯»å–å¹¶è°ƒæ•´å­—å¹•
            with open(srt_file, 'r', encoding='utf-8') as in_srt:
                content = in_srt.read()
                adjusted_content = adjust_srt_timestamps(content, total_duration)
                out_srt.write(adjusted_content)
                out_srt.write('\n')
            
            # ç´¯åŠ å½“å‰éŸ³é¢‘æ—¶é•¿
            audio = AudioSegment.from_mp3(audio_file)
            total_duration += len(audio)

def adjust_srt_timestamps(srt_content: str, offset_ms: int) -> str:
    """
    è°ƒæ•´SRTå­—å¹•çš„æ—¶é—´æˆ³
    
    Args:
        srt_content: åŸå§‹SRTå†…å®¹
        offset_ms: æ—¶é—´åç§»é‡(æ¯«ç§’)
        
    Returns:
        è°ƒæ•´åçš„SRTå†…å®¹
    """
    if offset_ms == 0:
        return srt_content
        
    lines = srt_content.split('\n')
    adjusted_lines = []
    
    for line in lines:
        if '-->' in line:
            # è¿™æ˜¯æ—¶é—´è½´è¡Œ
            parts = line.split('-->')
            start, end = parts[0].strip(), parts[1].strip()
            
            # è°ƒæ•´æ—¶é—´
            start = adjust_time(start, offset_ms)
            end = adjust_time(end, offset_ms)
            
            line = f"{start} --> {end}"
        
        adjusted_lines.append(line)
    
    return '\n'.join(adjusted_lines)

def adjust_time(time_str: str, offset_ms: int) -> str:
    """
    è°ƒæ•´å•ä¸ªæ—¶é—´æˆ³
    
    Args:
        time_str: æ—¶é—´å­—ç¬¦ä¸² (HH:MM:SS,mmm)
        offset_ms: åç§»é‡(æ¯«ç§’)
        
    Returns:
        è°ƒæ•´åçš„æ—¶é—´å­—ç¬¦ä¸²
    """
    # è§£ææ—¶é—´
    hh_mm_ss, ms = time_str.split(',')
    hh, mm, ss = hh_mm_ss.split(':')
    
    total_ms = (int(hh) * 3600 + int(mm) * 60 + int(ss)) * 1000 + int(ms)
    total_ms += offset_ms
    
    # è½¬æ¢å›æ—¶é—´æ ¼å¼
    new_ms = total_ms % 1000
    total_seconds = total_ms // 1000
    new_ss = total_seconds % 60
    total_minutes = total_seconds // 60
    new_mm = total_minutes % 60
    new_hh = total_minutes // 60
    
    return f"{new_hh:02d}:{new_mm:02d}:{new_ss:02d},{new_ms:03d}"

# å®šä¹‰å°† SubRipTime å¯¹è±¡è½¬æ¢ä¸ºç§’æ•°çš„å‡½æ•°
def time2sec(subriptime):
    return (
        subriptime.hours * 3600 +
        subriptime.minutes * 60 +
        subriptime.seconds +
        subriptime.milliseconds / 1000.0
    )

# å®šä¹‰åˆå¹¶å­—å¹•æ¡ç›®çš„å‡½æ•°
def merge_subtitles(srt, max_duration_s) -> None:
    subtitles = pysrt.open(srt)
    merged_subtitles = []
    current_sub = None

    for sub in subtitles:
        if current_sub is None:
            current_sub = sub
        else:
            # è®¡ç®—å½“å‰å­—å¹•æ¡ç›®çš„å¼€å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´
            start_time = time2sec(sub.start)
            end_time = time2sec(sub.end)
               
            # è®¡ç®—ä¸Šä¸€ä¸ªå­—å¹•æ¡ç›®çš„ç»“æŸæ—¶é—´
            current_start_time = time2sec(current_sub.start)
            current_end_time = time2sec(current_sub.end)
        
            # å¦‚æœå½“å‰å­—å¹•æ¡ç›®çš„å¼€å§‹æ—¶é—´ä¸ä¸Šä¸€ä¸ªæ¡ç›®çš„ç»“æŸæ—¶é—´ç›¸å·®ä¸è¶…è¿‡ 0.1 ç§’ï¼Œ
            # å¹¶ä¸”åˆå¹¶åçš„æ—¶é—´è·¨åº¦ä¸è¶…è¿‡ max_duration_s ç§’ï¼Œ
            # åˆ™åˆå¹¶è¿™ä¸¤ä¸ªæ¡ç›®ã€‚
            if start_time - current_end_time <= 0.1 and (end_time - current_start_time) <= max_duration_s:
                current_sub.end = sub.end
                current_sub.text = current_sub.text.strip() + "" + sub.text.strip()
            else:
                # å¦åˆ™ï¼Œå°†å½“å‰åˆå¹¶çš„å­—å¹•æ¡ç›®æ·»åŠ åˆ°ç»“æœåˆ—è¡¨ä¸­ï¼Œå¹¶å¼€å§‹æ–°çš„å­—å¹•æ¡ç›®ã€‚
                merged_subtitles.append(current_sub)
                current_sub = sub
                
    # æ·»åŠ æœ€åä¸€ä¸ªå­—å¹•æ¡ç›®
    if current_sub:
        merged_subtitles.append(current_sub)
    
    # å°†åˆå¹¶åçš„å­—å¹•æ¡ç›®åˆ—è¡¨è½¬æ¢ä¸º SubRipFile å¯¹è±¡
    merged_subrip_file = pysrt.SubRipFile(merged_subtitles)
    # ä¿å­˜åˆå¹¶åçš„å­—å¹•åˆ°æ–°çš„ .srt æ–‡ä»¶
    merged_subrip_file.save(srt, encoding="utf-8")

def draw_text_on_frame(frame, text, font, color, position, screen_size, stroke_width, stroke_color, use_shadow):
    """ï¼ˆé«˜ä½é…éƒ½è°ƒç”¨ï¼‰åœ¨è§†é¢‘å¸§ä¸Šç»˜åˆ¶æ–‡æœ¬"""
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_pil = Image.fromarray(frame_rgb)
    draw = ImageDraw.Draw(frame_pil)

    text_bbox = draw.textbbox((0, 0), text, font=font)
    text_width = text_bbox[2] - text_bbox[0]
    text_height = text_bbox[3] - text_bbox[1]
    
    if isinstance(position[0], str) and position[0].lower() == "center":
        x = (screen_size[0] - text_width) // 2
    else:
        x = position[0]
    
    if isinstance(position[1], str) and position[1].lower() == "middle":
        y = (screen_size[1] - text_height) // 2
        y -= text_bbox[1]
    else:
        y = position[1]

    draw.text(
        (x, y),
        text,
        font=font,
        fill=color[::-1],
        stroke_width=stroke_width if use_shadow else 0,
        stroke_fill=stroke_color[::-1] if use_shadow else None
    )
    return cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)

def render_frame(args):
    """ä¿®æ”¹åæ”¯æŒåŠ¨æ€å¸§ç‡çš„ç‰ˆæœ¬"""
    frame_idx, sub_times, bg_with_title, screen_size, font, text_color, position, stroke_width, stroke_color, use_shadow, fps = args 
    frame_time = frame_idx / fps 
    frame = bg_with_title.copy()
    
    for start, end, text in sub_times:
        if start <= frame_time < end:
            frame = draw_text_on_frame(
                frame=frame,
                text=text,
                font=font,
                color=text_color,
                position=position,
                screen_size=screen_size,
                stroke_width=stroke_width,
                stroke_color=stroke_color,
                use_shadow=use_shadow
            )
    return frame.tobytes()

# é«˜ä½é…éƒ½è°ƒç”¨ç”Ÿæˆæ‹¼è‰²èƒŒæ™¯
def create_gradient_background(width, height): 
    BG_COLOR = (243, 66, 26)  # è“è‰² RGB(80,80,80)ç°è‰²
    CANVAS_COLOR = (93, 20, 0)  # è“é»‘ RGBï¼ˆ0,0,0ï¼‰é»‘è‰²
    bg = np.zeros((height, width, 3), dtype=np.uint8)
    # ä¸Šé»‘ï¼ˆ25%é«˜åº¦ï¼‰
    bg[:height//4, :] = CANVAS_COLOR
    # ä¸­ç°ï¼ˆ50%é«˜åº¦ï¼‰
    bg[height//4:height*3//4, :] = BG_COLOR 
    # ä¸‹é»‘ï¼ˆ25%é«˜åº¦ï¼‰
    bg[height*3//4:, :] = CANVAS_COLOR
    return bg

def create_video_multi(srt_filename, audio_filename, output_filename, screen_size, title_txt):
    """å¤šçº¿ç¨‹ç‰ˆæœ¬"""
    start_time = time.time()
    try:
        # æ ¸å¿ƒå‚æ•°é…ç½®
        FPS = 24
        TITLE_FONT_SIZE = 85
        TITLE_COLOR = (93, 20, 0) # è“é»‘ BGR(171, 229, 243)é‡‘è‰²
        TITLE_STROKE_COLOR = (200, 200, 200) # ç°è‰²
        TITLE_STROKE_WIDTH = 2
        TITLE_Y = int(screen_size[1] * 0.5) #250
        SUB_FONT_SIZE = 100
        SUB_COLOR = (0, 0, 255) # çº¢è‰² BGR(171, 229, 243)é‡‘è‰²
        SUB_STROKE_COLOR = (0, 0, 0)
        SUB_STROKE_WIDTH = 2
        SUB_POSITION = ("center", "middle")
        SUB_USE_SHADOW = False

        subs = pysrt.open(srt_filename, encoding='utf-8')
        sub_times = [(time2sec(sub.start), time2sec(sub.end), sub.text) for sub in subs]
        audio = AudioSegment.from_file(audio_filename)
        total_duration = max(time2sec(subs[-1].end), len(audio)/1000)

        # ç”Ÿæˆæ‹¼è‰²èƒŒæ™¯
        bg_image = create_gradient_background(screen_size[0], screen_size[1])

        try:
            font_path = current_app.config['VIDEO_FONT_DIR'] / 'ceym.ttf'
            font_title = ImageFont.truetype(font_path, TITLE_FONT_SIZE)
            font_sub = ImageFont.truetype(font_path, SUB_FONT_SIZE)
        except:
            font_title = ImageFont.load_default()
            font_sub = ImageFont.load_default()

        bg_with_title = draw_text_on_frame(
            frame=bg_image,
            text=title_txt,
            font=font_title,
            color=TITLE_COLOR,
            position=("center", TITLE_Y),
            screen_size=screen_size,
            stroke_width=TITLE_STROKE_WIDTH,
            stroke_color=TITLE_STROKE_COLOR,
            use_shadow=False
        )

        # FFmpegå‚æ•°
        cmd = [
        'ffmpeg', '-y',
        '-thread_queue_size', '2048',
        '-f', 'rawvideo',
        '-vcodec', 'rawvideo',
        '-s', f'{screen_size[0]}x{screen_size[1]}',
        '-pix_fmt', 'bgr24',
        '-r', '24',
        '-i', '-',
        '-i', str(audio_filename),  # ç¡®ä¿è·¯å¾„æ˜¯å­—ç¬¦ä¸²
        '-preset', 'fast',
        # '-c:v', 'h264_nvenc',          # æ”¹ç”¨ NVIDIA NVENC ç¼–ç  
        # '-pix_fmt', 'nv12',            # NVENC æ¨èæ ¼å¼ï¼ˆåŸ yuv420pï¼‰
        # '-cq', '23',                   # NVENC è´¨é‡å‚æ•°ï¼ˆåŸ global_qualityï¼‰
        # '-rc', 'vbr',                  # NVIDIAæ–°å¢ï¼šç ç‡æ§åˆ¶æ¨¡å¼ï¼ˆå¯å˜ç ç‡ï¼‰
        # '-b:v', '0',                   # NVIDIAæ–°å¢ï¼šè‡ªåŠ¨ç ç‡ï¼ˆåŸºäº cq å€¼ï¼‰
        '-c:v', 'h264_qsv',           # Intel åŠ é€Ÿ
        '-pix_fmt', 'yuv420p',        # Intel é»˜è®¤æ ¼å¼
        '-global_quality', '23',      # Intel ç¼–ç è´¨é‡å‚æ•°
        '-c:a', 'aac',
        '-metadata', f'title={title_txt}',
        '-metadata', 'encoder=FFmpeg',
        str(output_filename)  # ç¡®ä¿è·¯å¾„æ˜¯å­—ç¬¦ä¸²
    ]

        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor, \
             subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) as process:
            
            # åœ¨ create_video_multi ä¸­æ„å»ºå‚æ•°æ—¶åŠ å…¥ fps
            frame_args = [
                (i, sub_times, bg_with_title, screen_size, font_sub, 
                SUB_COLOR, SUB_POSITION, SUB_STROKE_WIDTH, SUB_STROKE_COLOR, SUB_USE_SHADOW, FPS)  # æ–°å¢ FPS
                for i in range(int(total_duration * FPS))  # è¿™é‡Œä¹Ÿä½¿ç”¨ FPS æ›¿ä»£ç¡¬ç¼–ç å€¼
            ]
            
            for frame_data in executor.map(render_frame, frame_args):
                process.stdin.write(frame_data)

        print(f"è§†é¢‘ç”Ÿæˆå®Œæˆ | è€—æ—¶: {time.time()-start_time:.1f}ç§’")

    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        raise

def create_video_single(srt_filename, audio_filename, output_filename, screen_size, title_txt):
    """å•çº¿ç¨‹ç‰ˆæœ¬"""
    start_time = time.time()
    try:
        # æ ¸å¿ƒå‚æ•°é…ç½®
        SCALE = 640 / 1080  # ç›´æ¥ä½¿ç”¨åˆ†æ•°å…³ç³»
        PROCESS_SIZE = (int(screen_size[0] * SCALE), int(screen_size[1] * SCALE)) # PROCESS_SIZE = (640, 1136)
        FPS = 18
        TITLE_FONT_SIZE = 50
        TITLE_COLOR = (93, 20, 0)
        TITLE_STROKE_COLOR = (200, 200, 200)
        TITLE_STROKE_WIDTH = 2
        TITLE_Y = int(PROCESS_SIZE[1] * 0.5) # int(PROCESS_SIZE[1] * 0.13)
        SUB_FONT_SIZE = 59
        SUB_COLOR = (171, 229, 243)
        SUB_STROKE_COLOR = (0, 0, 0)
        SUB_STROKE_WIDTH = 0
        SUB_POSITION = ("center", "middle")
        SUB_USE_SHADOW = False

        subs = pysrt.open(srt_filename, encoding='utf-8')
        sub_times = [(time2sec(sub.start), time2sec(sub.end), sub.text) for sub in subs]

        # ç”Ÿæˆæ‹¼è‰²èƒŒæ™¯
        bg = create_gradient_background(PROCESS_SIZE[0], PROCESS_SIZE[1])

        font_path = current_app.config['VIDEO_FONT_DIR'] / 'ceym.ttf'
        if not os.path.exists(font_path):
            raise RuntimeError("å¿…é¡»çš„å­—ä½“æ–‡ä»¶ç¼ºå¤±: ceym.ttf")
        
        font_title = ImageFont.truetype(font_path, TITLE_FONT_SIZE)
        font_sub = ImageFont.truetype(font_path, SUB_FONT_SIZE)

        title_layer = draw_text_on_frame(
            frame=bg,
            text=title_txt,
            font=font_title,
            position=("center", TITLE_Y),
            screen_size=PROCESS_SIZE,
            color=TITLE_COLOR,
            stroke_width=TITLE_STROKE_WIDTH,
            stroke_color=TITLE_STROKE_COLOR,
            use_shadow=False
        )

        # ä¿æŒåŸæœ‰cmdå‚æ•°ï¼ˆåŒ…æ‹¬æ³¨é‡Šï¼‰å®Œå…¨ä¸å˜
        cmd = [
            'ffmpeg', '-y',
            '-thread_queue_size', '2048',
            '-f', 'rawvideo',
            '-vcodec', 'rawvideo',
            '-s', f'{PROCESS_SIZE[0]}x{PROCESS_SIZE[1]}',
            '-pix_fmt', 'bgr24',
            '-r', str(FPS),
            '-i', '-',
            '-thread_queue_size', '512',
            '-i', audio_filename,
            '-c:v', 'libx264',
            '-profile:v', 'main',
            '-pix_fmt', 'yuv420p',
            '-movflags', '+faststart',
            '-preset', 'fast',
            '-crf', '23',
            '-x264-params', 'ref=4:bframes=0',
            '-c:a', 'aac',
            '-ar', '44100',
            '-b:a', '128k',
            '-ac', '1',
            '-metadata', f'title={title_txt}',
            '-metadata', 'encoder=FFmpeg',
            output_filename
        ]

        with subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) as proc:
            for frame_idx in range(int(time2sec(subs[-1].end) * FPS)):
                frame_time = frame_idx / FPS
                frame = title_layer.copy()
                
                for start, end, text in sub_times:
                    if start <= frame_time < end:
                        frame = draw_text_on_frame(
                            frame=frame,
                            text=text,
                            font=font_sub,
                            position=SUB_POSITION, 
                            screen_size=PROCESS_SIZE,
                            color=SUB_COLOR,
                            stroke_width=SUB_STROKE_WIDTH,
                            stroke_color=SUB_STROKE_COLOR,
                            use_shadow=SUB_USE_SHADOW
                        )
                        break
                
                proc.stdin.write(frame.tobytes())
            
            proc.stdin.close()
            proc.wait()

        print(f"è§†é¢‘ç”ŸæˆæˆåŠŸ | è€—æ—¶: {time.time()-start_time:.1f}ç§’")
        return True

    except Exception as e:
        print(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
        return False
     
# åˆ›å»ºå°é¢postistå’Œvideoistå…±ç”¨
def creating_cover(text, keywords, cover_filename) -> None:

    # ç¡®ä¿ keywords æ˜¯ä¸€ä¸ªåˆ—è¡¨
    if isinstance(keywords, str):
        keywords = keywords.split(',')

    # è®¾ç½®è·¯å¾„
    html_template_path = Config.HTML_DIR / 'template-xhscover.html'
    html_file_path = Path('./tmp/working.html').resolve()
    os.makedirs(html_file_path.parent, exist_ok=True)

    # æ¸²æŸ“HTMLæ¨¡æ¿
    with open(html_template_path, 'r', encoding='utf-8') as file:
        template = Template(file.read())

    html_content = template.render(text=text, keywords=keywords)
    
    with open(html_file_path, 'w', encoding='utf-8') as file:
        file.write(html_content)

    # è®¾ç½®Chromeé€‰é¡¹
    driver_path = os.getenv('CHROME_DRIVER_PATH')
    if not driver_path:
        raise ValueError("ç¯å¢ƒå˜é‡ CHROME_DRIVER_PATH æœªè®¾ç½®ï¼Œè¯·æŒ‡å®šChromeDriverè·¯å¾„ã€‚")
    service = Service(driver_path)
    chrome_options = Options()
    chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£

    # å¯åŠ¨Chromeæµè§ˆå™¨
    driver = webdriver.Chrome(options=chrome_options, service=service)
    driver.set_window_size(1200, 1600) # è®¾ç½®æµè§ˆå™¨çª—å£å¤§å°

    try:
        # æ‰“å¼€HTMLæ–‡ä»¶
        driver.get(f'file://{html_file_path}')
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.ID, 'text-container'))
        )

        # è·å–é¡µé¢æˆªå›¾
        screenshot = driver.execute_cdp_cmd("Page.captureScreenshot", {"format": "png", "fromSurface": True, "captureBeyondViewport": True})
        with open(cover_filename, 'wb') as f:
            img = base64.b64decode(screenshot['data'])
            f.write(img)
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯ï¼š{e}")
    finally:
        # å…³é—­æµè§ˆå™¨
        driver.quit()


# gpt part ç”Ÿæˆæ­£æ–‡ï¼Œpostist_core.pyé‡Œä¹Ÿæœ‰ï¼Œä½†åç¼€ä¸åŒè¡¨ç¤ºapiä¸åŒ
def generating_byds(content, prompt_path):
    client = OpenAI(
        api_key=os.getenv('API_KEY_DS'),
        base_url=os.getenv('URL_DS'), 
    )
    # å®šä¹‰æç¤ºè¯
    with open(prompt_path, 'r', encoding='utf-8') as file:
        your_prompt = file.read()
    your_prompt = your_prompt + content
    try:
        completion = client.chat.completions.create(
            model='deepseek-chat',   
            messages = [
                {
                    "role": "user",
                    "content": your_prompt
                }
            ],
            stream=False
        )
        print(completion.choices[0].message.content)
        answer = completion.choices[0].message.content
    except Exception as e:
        print("æç¤º", e)
        answer = "æ•æ„Ÿè¯censored by Deepseek"
    print("DeepSeekå¤§æ¨¡å‹å·¥ä½œä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»")
    return answer

# gpt part ç”Ÿæˆæ­£æ–‡ï¼Œpostist_core.pyé‡Œä¹Ÿæœ‰ï¼Œä½†åç¼€ä¸åŒè¡¨ç¤ºapiä¸åŒ
def generating_bykm(content, prompt_path):
    client = OpenAI(
        api_key=os.getenv('API_KEY_KIMI'),
        base_url=os.getenv('URL_KIMI'), 
    )
    # å®šä¹‰æç¤ºè¯
    with open(prompt_path, 'r', encoding='utf-8') as file:
        your_prompt = file.read()
    your_prompt = your_prompt + content
    try:
        completion = client.chat.completions.create(
            model='moonshot-v1-8k',   
            messages = [
                {
                    "role": "user",
                    "content": your_prompt
                }
            ],
            stream=False
        )
        print(completion.choices[0].message.content)
        answer = completion.choices[0].message.content
    except Exception as e:
        print("æç¤º", e)
        answer = "æ•æ„Ÿè¯censored by Moonshot"
    print("Moonshotå¤§æ¨¡å‹å·¥ä½œä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»")
    return answer

# gpt part ç”Ÿæˆæ­£æ–‡
def generating_jskb(content, prompt_path):
    client = OpenAI(
        api_key=os.getenv('API_KEY_DS'),
        base_url=os.getenv('URL_DS'), 
    )
    # å®šä¹‰æç¤ºè¯
    with open(prompt_path, 'r', encoding='utf-8') as file:
        your_prompt = file.read()
    # your_prompt = your_prompt + content
    try:
        completion = client.chat.completions.create(
            model='deepseek-chat',   
            messages = [{"role": "system", "content": your_prompt}, {"role": "user", "content": content}],
            stream=False,
            temperature=0.4,          # é™ä½éšæœºæ€§
            # max_tokens=4096,          # é˜²æ­¢è¿‡é•¿
            top_p=0.9,                # å¹³è¡¡å¤šæ ·æ€§
            frequency_penalty=0.5,    # å‡å°‘é‡å¤
            presence_penalty=0.3,     # é€‚åº¦æ§åˆ¶ä¸»é¢˜è·³è·ƒ
            response_format={'type': 'json_object'}
        )
        answer = completion.choices[0].message.content
    except Exception as e:
        print("æç¤º", e)
        answer = "æ•æ„Ÿè¯censored by Deepseek"
    print("DeepSeekå¤§æ¨¡å‹å·¥ä½œä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»")
    return answer

# ä»ç½‘é¡µä¸­æå–æ–‡æœ¬
def extractting(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()

        # è§£æç½‘é¡µå†…å®¹
        soup = BeautifulSoup(response.text, 'html.parser')

        # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
        text = soup.get_text(separator='\n', strip=True)
        return text

    except requests.exceptions.HTTPError as errh:
        print(f"HTTP Error: {errh}")
        return ""
    except requests.exceptions.RequestException as err:
        print(f"è¯·æ±‚é”™è¯¯: {err}")
        return ""

# ç”Ÿæˆ Basic Auth Token
def basic_auth_token(username, password):
    credentials = f"{username}:{password}"
    token = base64.b64encode(credentials.encode('utf-8')).decode('utf-8')
    return f"Basic {token}"

# å‘å¸ƒæ–‡ç« å¹¶å…³è”å›¾ç‰‡
def posting(wp_url, token, data):
    url = f"{wp_url}/wp-json/wp/v2/posts"
    
    headers = {
        "Authorization": token,  # æ·»åŠ  Basic Auth
    }
    response = requests.post(
        url,
        headers=headers,
        json=data,
    )
    if response.status_code == 201:
        return response.json()  # è¿”å›æ–‡ç« ä¿¡æ¯
    else:
        raise Exception(f"Failed to create post: {response.status_code} - {response.text}")

def getting_picture(query, dir, filename, aspect_ratio):
    """
    Get an image from Unsplash with specified aspect ratio
    
    Args:
        query (str): Search query for the image
        dir (str): Directory to save the image
        filename (str): Base filename (without extension)
        aspect_ratio (int): 
            1 for landscape (horizontal),
            2 for portrait (vertical),
            3 for square (default: 1)
    
    Returns:
        str: Path to saved image or None if failed
    """
    ACCESS_KEY = os.environ.get("UNP_AKEY")
    if not query:
        query = "global map"

    if not ACCESS_KEY:
        raise ValueError("Unsplash API access key not found in environment variables.")

    # Validate aspect ratio
    if aspect_ratio not in (1, 2, 3):
        raise ValueError("aspect_ratio must be 1 (landscape), 2 (portrait), or 3 (square)")

    # Map aspect ratio to Unsplash orientation parameter
    orientation_map = {
        1: "landscape",
        2: "portrait",
        3: "squarish"
    }
    orientation = orientation_map[aspect_ratio]
    per_page = 5

    # Construct API request URL
    url = (
        f"https://api.unsplash.com/search/photos"
        f"?client_id={ACCESS_KEY}"
        f"&query={query}"
        f"&orientation={orientation}"
        f"&per_page={per_page}"
    )

    # Send request
    response = requests.get(url)
    response.raise_for_status()

    # Parse JSON response
    data = response.json()
    if not data['results']:
        print("No matching images found")
        return None

    # Process image results
    for photo in data['results']:
        photo_url = photo['urls']['full']
        photo_description = photo.get('description', "No description")

        # Download image
        try:
            response = requests.get(photo_url)
            response.raise_for_status()
            image_data = response.content
            
            # Always use WebP extension
            file_extension = '.webp'
            # Create directory if not exists
            save_dir = Config.ARTICLE_DIR / dir
            os.makedirs(save_dir, exist_ok=True)
            # Construct full path with directory and filename
            filename = f"{filename}{file_extension}"
            filepath = save_dir / filename

            try:
                # Open the image with PIL
                img = Image.open(io.BytesIO(image_data))
                
                # Convert to RGB if needed (WebP doesn't support alpha channel)
                if img.mode in ('RGBA', 'P', 'LA'):
                    img = img.convert('RGB')
                
                # Verify aspect ratio matches request
                width, height = img.size
                ratio = width / height
                
                # Define acceptable ratio ranges for each type
                if aspect_ratio == 1 and ratio < 1.2:  # Landscape (w > h)
                    print(f"Skipping image - requested landscape but got portrait/square")
                    continue
                elif aspect_ratio == 2 and ratio > 0.8:  # Portrait (h > w)
                    print(f"Skipping image - requested portrait but got landscape/square")
                    continue
                elif aspect_ratio == 3 and not (0.9 < ratio < 1.1):  # Square (~1:1)
                    print(f"Skipping image - requested square but got landscape/portrait")
                    continue
                
                # Resize if too large
                max_dimension = 1920
                if max(img.size) > max_dimension:
                    ratio = max_dimension / max(img.size)
                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
                    img = img.resize(new_size, Image.LANCZOS)
                
                # Compression parameters for WebP
                quality = 85
                method = 6  # Default compression method (0-6)
                
                # Save directly as WebP
                buffer = io.BytesIO()
                img.save(buffer, format='WEBP', quality=quality, method=method)
                
                # If under 1MB, save directly
                if buffer.getbuffer().nbytes <= 1024 * 1024:
                    with open(filepath, "wb") as f:
                        f.write(buffer.getvalue())
                    print(f"WebP image saved: {filepath} (Size: {buffer.getbuffer().nbytes/1024:.1f}KB)")
                    print(f"Description: {photo_description}")
                    return str(filepath)

                # If still too large, try reducing quality
                print(f"Initial WebP size: {buffer.getbuffer().nbytes/1024:.1f}KB, compressing further...")
                
                while quality >= 30:  # Don't go below 30% quality
                    buffer = io.BytesIO()
                    img.save(buffer, format='WEBP', quality=quality, method=method)
                    
                    if buffer.getbuffer().nbytes <= 1024 * 1024:
                        with open(filename, "wb") as f:
                            f.write(buffer.getvalue())
                        print(f"Compressed WebP saved: {filename} (Size: {buffer.getbuffer().nbytes/1024:.1f}KB, Quality: {quality}%)")
                        print(f"Description: {photo_description}")
                        return filename
                    
                    # Reduce quality for next attempt
                    quality -= 10
                
                # If we get here, all attempts failed
                print("Failed to compress WebP below 1MB")
                continue
                
            except Exception as img_error:
                print(f"Image processing failed: {str(img_error)}")
                continue
                
        except Exception as download_error:
            print(f"Download failed: {str(download_error)}")
            continue

    print("No suitable images found")
    return None

def comfyui_picture(prompt, dir, filename, aspect_ratio):
    """ç”Ÿæˆå›¾ç‰‡å¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•ï¼ˆä½¿ç”¨bypy_å‰ç¼€+åºå·æ£€æµ‹æœ€æ–°æ–‡ä»¶ï¼‰
    
    å‚æ•°:
        prompt (str): å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
        dir (str): æœ€ç»ˆä¿å­˜ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
        filename (str): ä¸»æ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
        aspect_ratio (int): å›¾ç‰‡å°ºå¯¸æ¯”ä¾‹ 
            1: 768 * 512 (æ¨ªç‰ˆ)
            2: 512 * 768 (ç«–ç‰ˆ)
            3: 512 * 512 (æ–¹å½¢)
    """
    # ---------- é…ç½®åŒº ----------
    COMFYUI_API_URL = "http://127.0.0.1:8188/prompt"  # ComfyUI APIåœ°å€
    COMFYUI_OUTPUT_DIR = "C:\\pyproj\\ComfyUI-aki-v1.4\\output"  # ComfyUIè¾“å‡ºç›®å½•
    TIMEOUT = 600  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    FILE_PREFIX = "bypy_"  # å›ºå®šæ–‡ä»¶åå‰ç¼€
    # ---------------------------

    # æ ¹æ®æ¯”ä¾‹è®¾ç½®å®½é«˜
    if aspect_ratio == 1:
        width, height = 384, 256
    elif aspect_ratio == 2:
        width, height = 512, 768
    elif aspect_ratio == 3:
        width, height = 512, 512
    else:
        print(f"âš ï¸ æœªçŸ¥æ¯”ä¾‹å‚æ•° {aspect_ratio}ï¼Œä½¿ç”¨é»˜è®¤ 768x512")
        width, height = 768, 512

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(dir, exist_ok=True)

    # 1. å®šä¹‰å·¥ä½œæµ
    workflow = {
        "3": {
            "inputs": {
                "seed": int(datetime.now().timestamp()),
                "steps": 20,
                "cfg": 1,
                "sampler_name": "euler",
                "scheduler": "simple",
                "denoise": 1,
                "model": ["10", 0],
                "positive": ["15", 0],
                "negative": ["16", 0],
                "latent_image": ["5", 0]
            },
            "class_type": "KSampler"
        },
        "5": {
            "inputs": {
                "width": width,
                "height": height,
                "batch_size": 1
            },
            "class_type": "EmptyLatentImage"
        },
        "8": {
            "inputs": {
                "samples": ["3", 0],
                "vae": ["11", 0]
            },
            "class_type": "VAEDecode"
        },
        "10": {
            "inputs": {
                "unet_name": "flux1-dev-Q3_K_S.gguf"
            },
            "class_type": "UnetLoaderGGUF"
        },
        "11": {
            "inputs": {
                "vae_name": "FLUX.1-ae.safetensors"
            },
            "class_type": "VAELoader"
        },
        "12": {
            "inputs": {
                "clip_name1": "clip_l.safetensors",
                "clip_name2": "t5xxl_fp8_e4m3fn.safetensors",
                "type": "flux",
                "device": "default"
            },
            "class_type": "DualCLIPLoader"
        },
        "15": {
            "inputs": {
                "clip_l": prompt,
                "t5xxl": "",
                "guidance": 3.5,
                "speak_and_recognation": {"__value__": [False, True]},
                "clip": ["12", 0]
            },
            "class_type": "CLIPTextEncodeFlux"
        },
        "16": {
            "inputs": {
                "conditioning": ["15", 0]
            },
            "class_type": "ConditioningZeroOut"
        },
        "18": {
            "inputs": {
                "filename_prefix": FILE_PREFIX,  # ä½¿ç”¨å›ºå®šå‰ç¼€
                "images": ["8", 0]
            },
            "class_type": "SaveImage"
        }
    }

    # 2. æäº¤ç”Ÿæˆè¯·æ±‚
    try:
        print("ğŸ”„ æ­£åœ¨æäº¤ç”Ÿæˆè¯·æ±‚...")
        response = requests.post(COMFYUI_API_URL, json={"prompt": workflow})
        response.raise_for_status()
        prompt_id = response.json()["prompt_id"]
        print(f"âœ… ä»»åŠ¡å·²æäº¤ (ID: {prompt_id})")
    except Exception as e:
        print(f"âŒ æäº¤å¤±è´¥: {str(e)}")
        return None

    # 3. æ™ºèƒ½è½®è¯¢ï¼ˆæ£€æµ‹bypy_å‰ç¼€æ–‡ä»¶ä¸­åºå·æœ€å¤§çš„ï¼‰
    print("â³ æ­£åœ¨ç›‘å¬ç”ŸæˆçŠ¶æ€...")
    start_time = time.time()
    final_path = None

    while True:
        try:
            # è·å–æ‰€æœ‰bypy_å‰ç¼€çš„PNGæ–‡ä»¶
            prefix_files = [
                f for f in os.listdir(COMFYUI_OUTPUT_DIR)
                if f.startswith(FILE_PREFIX) and f.endswith(".png")
            ]

            if prefix_files:
                # æå–åºå·å¹¶æ‰¾åˆ°æœ€å¤§å€¼ï¼ˆä¾‹å¦‚ bypy_00003.png -> 3ï¼‰
                max_num = -1
                latest_file = None
                for f in prefix_files:
                    try:
                        # æå–æ–‡ä»¶åä¸­çš„æ•°å­—éƒ¨åˆ†
                        num_str = f[len(FILE_PREFIX):].split('.')[0]  # "00003"
                        num = int(num_str)  # è½¬æ¢ä¸ºæ•´æ•°
                        if num > max_num:
                            max_num = num
                            latest_file = f
                    except (IndexError, ValueError):
                        continue

                if latest_file:
                    src = os.path.join(COMFYUI_OUTPUT_DIR, latest_file)
                    temp_png_path = os.path.join(dir, f"{filename}.png")  # ä¸´æ—¶PNGæ–‡ä»¶
                    final_webp_path = os.path.join(dir, f"{filename}.webp")  # æœ€ç»ˆWebPæ–‡ä»¶
                    
                    # å¤åˆ¶åŸå§‹PNGæ–‡ä»¶
                    shutil.copy2(src, temp_png_path)
                    print(f"âœ… å·²æ‰¾åˆ°åŸå§‹æ–‡ä»¶: {latest_file}")
                    
                    try:
                        # ä½¿ç”¨Pillowè½¬æ¢ä¸ºWebP
                        from PIL import Image
                        with Image.open(temp_png_path) as img:
                            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆWebPä¸æ”¯æŒalphaé€šé“ï¼‰
                            if img.mode in ('RGBA', 'P', 'LA'):
                                img = img.convert('RGB')
                            
                            # WebPå‹ç¼©å‚æ•°
                            quality = 85
                            method = 6  # é»˜è®¤å‹ç¼©æ–¹æ³•
                            
                            # ä¿å­˜ä¸ºWebP
                            img.save(final_webp_path, format='WEBP', quality=quality, method=method)
                            final_path = final_webp_path
                            
                            # åˆ é™¤ä¸´æ—¶PNGæ–‡ä»¶
                            os.remove(temp_png_path)
                            
                            print(f"âœ… å·²è½¬æ¢ä¸ºWebP: {final_webp_path}")
                            print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(final_webp_path)/1024:.1f}KB")
                            return final_path
                    except Exception as img_error:
                        print(f"âš ï¸ WebPè½¬æ¢å¤±è´¥ï¼Œä¿ç•™PNGæ ¼å¼: {str(img_error)}")
                        final_path = temp_png_path
                        return final_path

            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            history_url = f"{COMFYUI_API_URL.rstrip('prompt')}history/{prompt_id}"
            history_data = requests.get(history_url).json()
            
            if prompt_id in history_data:
                status = history_data[prompt_id]
                if status["status"]["completed"]:
                    print("âœ… ä»»åŠ¡å·²å®Œæˆ")
                    # æœ€ç»ˆæ£€æŸ¥ä¸€æ¬¡æ–‡ä»¶
                    prefix_files = [f for f in os.listdir(COMFYUI_OUTPUT_DIR)
                                  if f.startswith(FILE_PREFIX) and f.endswith(".png")]
                    if prefix_files:
                        # ç›´æ¥æŒ‰å­—ç¬¦ä¸²æ’åºå–æœ€å¤§å€¼ï¼ˆbypy_00003 > bypy_00002ï¼‰
                        latest_file = max(prefix_files)
                        src = os.path.join(COMFYUI_OUTPUT_DIR, latest_file)
                        temp_png_path = os.path.join(dir, f"{filename}.png")
                        final_webp_path = os.path.join(dir, f"{filename}.webp")
                        
                        shutil.copy2(src, temp_png_path)
                        print(f"ğŸ”„ æ‰¾åˆ°æœ€ç»ˆæ–‡ä»¶: {latest_file}")
                        
                        try:
                            from PIL import Image
                            with Image.open(temp_png_path) as img:
                                if img.mode in ('RGBA', 'P', 'LA'):
                                    img = img.convert('RGB')
                                
                                quality = 85
                                method = 6
                                
                                img.save(final_webp_path, format='WEBP', quality=quality, method=method)
                                final_path = final_webp_path
                                os.remove(temp_png_path)
                                
                                print(f"ğŸ”„ æœ€ç»ˆè½¬æ¢ä¸ºWebP: {final_webp_path}")
                                return final_path
                        except Exception as img_error:
                            print(f"âš ï¸ æœ€ç»ˆWebPè½¬æ¢å¤±è´¥ï¼Œä¿ç•™PNG: {str(img_error)}")
                            final_path = temp_png_path
                            return final_path
                    return final_path
                elif status["status"]["failed"]:
                    print("âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
                    return None

            # è¶…æ—¶å¤„ç†
            elapsed = time.time() - start_time
            if elapsed > TIMEOUT:
                print(f"â° è¶…è¿‡{TIMEOUT}ç§’æœªå®Œæˆï¼Œç»ˆæ­¢ç­‰å¾…")
                return None

            time.sleep(1)  # é™ä½CPUå ç”¨

        except Exception as e:
            print(f"âš ï¸ è½®è¯¢å‡ºé”™: {str(e)}")
            time.sleep(5)

# å¤„ç†å›¾ç‰‡ä¸Šä¼ 
def upload_image(wp_url, token, image_path):
    url = f"{wp_url}/wp-json/wp/v2/media"
    headers = {
        "Content-Disposition": f'attachment; filename={os.path.basename(image_path)}',
        "Content-Type": f"image/{os.path.splitext(image_path)[1][1:]}",  # åŠ¨æ€è®¾ç½® Content-Type
        "Authorization": token,  # æ·»åŠ  Basic Auth
    }

    # å°è¯•ä¸Šä¼ å›¾ç‰‡
    with open(image_path, "rb") as file:
        response = requests.post(url, headers=headers, data=file)

    # å¦‚æœä¸Šä¼ æˆåŠŸï¼Œè¿”å› media_id å’Œ image_url
    if response.status_code == 201:
        return response.json()["id"], response.json()["source_url"]

    # å¦‚æœè¿”å› 502ï¼Œå°è¯•æ ¹æ®æ–‡ä»¶åæŸ¥æ‰¾åª’ä½“åº“ä¸­çš„å›¾ç‰‡
    elif response.status_code == 502:
        print("502 error, trying to find image by filename...")
        filename = os.path.basename(image_path)
        name, ext = os.path.splitext(filename)
        # æ·»åŠ  "-scaled" åˆ°æ–‡ä»¶å
        filename = name + "-scaled" + ext
        search_url = f"{wp_url}/wp-json/wp/v2/media"
        params = {
            "search": filename  # æ ¹æ®æ–‡ä»¶åæœç´¢
        }
        search_response = requests.get(search_url, headers={"Authorization": token}, params=params)

        # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡ï¼Œè¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹çš„ id å’Œ url
        if search_response.status_code == 200 and search_response.json():
            media_item = search_response.json()[0]
            return media_item["id"], media_item["source_url"]

        # å¦‚æœæœªæ‰¾åˆ°ï¼Œé‡æ–°å°è¯•ä¸Šä¼ 
        else:
            with open(image_path, "rb") as file:
                retry_response = requests.post(url, headers=headers, data=file)
            if retry_response.status_code == 201:
                return retry_response.json()["id"], retry_response.json()["source_url"]
            else:
                raise Exception(f"Failed to upload image after retry: {retry_response.status_code} - {retry_response.text}")

    # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡ºå¼‚å¸¸
    else:
        raise Exception(f"Failed to upload image: {response.status_code} - {response.text}")
    
def process_markdown_images(markdown_content, wp_url, token, dir):
    """
    å¤„ç†Markdownä¸­çš„æ‰€æœ‰å›¾ç‰‡ï¼Œä¸‹è½½å¹¶ä¸Šä¼ åˆ°WordPressï¼Œç„¶åæ›¿æ¢URL
    
    å‚æ•°:
        markdown_content: Markdownæ–‡æœ¬å†…å®¹
        wp_url: WordPressç«™ç‚¹URL
        token: WordPress APIè®¤è¯token
        dir: ä¸‹è½½ç›®å½•åç§°
    
    è¿”å›:
        å¤„ç†åçš„Markdownå†…å®¹
        å›¾ç‰‡ä¿¡æ¯å­—å…¸ {åŸå§‹å¼•ç”¨: {url: str, id: int}}
    """
    # åˆ›å»ºæŒ‰æ—¶é—´çš„ç›®å½•
    download_dir = Config.ARTICLE_DIR / dir
    os.makedirs(download_dir, exist_ok=True)
    
    # æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒæ—¶åŒ¹é…alt_textå’Œurl
    pattern = r'!\[(.*?)\]\((.*?)\)'  # æ­£ç¡®çš„æ¨¡å¼
    matches = re.findall(pattern, markdown_content)
    image_refs = list(set(matches))  # å»é‡å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
    
    print(f"å‘ç° {len(image_refs)} ä¸ªå›¾ç‰‡å¼•ç”¨: {image_refs}")
    if not image_refs:
        return markdown_content, {}
    
    image_info = {}
    counter = 1
    COMFYUI_API_URL = "http://127.0.0.1:8188/prompt"  # ComfyUI APIåœ°å€
    # ç›´æ¥æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
    try:
        response = requests.get(COMFYUI_API_URL, timeout=5)
        use_comfyui = response.status_code < 400  # 200-399çŠ¶æ€ç è¡¨ç¤ºæœåŠ¡å¯ç”¨
    except (requests.ConnectionError, requests.Timeout):
        use_comfyui = False

    for alt_text, original_url in image_refs:
        try:
            # ä¸‹è½½å›¾ç‰‡
            keyword = alt_text if alt_text else "Global Map" # é»˜è®¤å…³é”®è¯
            filename = f"{counter:02d}"
            # æ ¹æ®æœåŠ¡æ˜¯å¦è¿è¡Œé€‰æ‹©ä¸åŒçš„æ–¹æ³•
            image_path = comfyui_picture(keyword, download_dir, filename, 1) if use_comfyui else getting_picture(keyword, download_dir, filename, 1)
        
            if not image_path:
                continue
                
            # ä¸Šä¼ å›¾ç‰‡
            media_id, image_url = upload_image(wp_url, token, image_path)
            
            # ä¿å­˜å›¾ç‰‡ä¿¡æ¯ï¼ˆä½¿ç”¨å®Œæ•´åŸå§‹å¼•ç”¨ä½œä¸ºé”®ï¼‰
            original_ref = f"![{alt_text}]({original_url})"
            image_info[original_ref] = {
                "url": image_url,
                "id": media_id
            }
            
            counter += 1
            
        except Exception as e:
            print(f"å¤„ç†å›¾ç‰‡ {original_url} å¤±è´¥: {str(e)}")
            continue
    
    # æ›¿æ¢Markdownä¸­çš„å›¾ç‰‡å¼•ç”¨
    for original_ref, info in image_info.items():
        # ä»åŸå§‹å¼•ç”¨ä¸­æå–alt_text
        alt_match = re.match(r'!$$(.*?)$$', original_ref)
        alt_text = alt_match.group(1) if alt_match else ""
        
        markdown_content = markdown_content.replace(
            original_ref,
            f"![{alt_text}]({info['url']})"
        )
    
    return markdown_content, image_info

def markdown_to_html(md_text):
    """
    å¢å¼ºç‰ˆ Markdown è½¬ HTMLï¼š
    1. è‡ªåŠ¨æå– YAML front matterï¼ˆå¦‚æ ‡é¢˜ã€ä½œè€…ç­‰ï¼‰
    2. ç»Ÿä¸€æ³¨å…¥æ ·å¼ï¼ˆé€‚é…å¾®ä¿¡/WordPressï¼‰
    è¿”å›ï¼š
        - html_content (str): å¤„ç†åçš„HTML
        - metadata (dict): ä»YAMLè§£æçš„å…ƒæ•°æ®ï¼ˆè‹¥æ— YAMLåˆ™è¿”å›ç©ºå­—å…¸ï¼‰
    """
    # åˆ†ç¦» YAML front matter å’Œ Markdown æ­£æ–‡
    metadata = {}
    content = md_text
    
    if md_text.startswith('---'):
        parts = md_text.split('---', 2)
        if len(parts) > 2:
            try:
                metadata = yaml.safe_load(parts[1]) or {}  # è§£æYAML
                content = parts[2].strip()                 # å‰©ä½™éƒ¨åˆ†æ˜¯æ­£æ–‡
            except yaml.YAMLError as e:
                print(f"âš ï¸ YAMLè§£æå¤±è´¥: {e}")

    # è½¬æ¢Markdownä¸ºHTML
    html = markdown.markdown(content, extensions=['extra'])
    soup = BeautifulSoup(html, 'html.parser')

    # ç»Ÿä¸€æ ·å¼è¡¨ï¼ˆå…¼é¡¾å¾®ä¿¡å’ŒWordPressï¼‰
    unified_styles = {
        "h2": "color: #1a73e8; border-left: 4px solid #1a73e8; padding: 10px 15px; margin: 20px 0; font-size: 18px !important;",
        "p": "line-height: 1.6; margin: 10px 0;",
        "img": "max-width: 100%; height: auto; display: block; margin: 15px auto;",
        "ul": "padding-left: 20px;",
        "li": "margin: 5px 0;",
        "blockquote": "border-left: 3px solid #ddd; padding-left: 15px; color: #666;"
    }

    # æ³¨å…¥æ ·å¼
    for tag, style in unified_styles.items():
        for element in soup.find_all(tag):
            element['style'] = style

    return str(soup), metadata  # è¿”å›HTMLå’Œå…ƒæ•°æ®

def convert_webp_to_jpg(directory):
    # éå†æŒ‡å®šç›®å½•
    for filename in os.listdir(directory):
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯.webpæ–‡ä»¶
        if filename.endswith(".webp"):
            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(directory, filename)
            # æ‰“å¼€.webpæ–‡ä»¶
            with Image.open(file_path) as img:
                # æ„å»ºæ–°çš„æ–‡ä»¶åå’Œè·¯å¾„
                new_filename = filename[:-5] + ".jpg"
                new_file_path = os.path.join(directory, new_filename)
                # å°†å›¾åƒè½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå› ä¸ºJPGä¸æ”¯æŒé€æ˜é€šé“ï¼‰
                img_rgb = img.convert('RGB')
                # ä¿å­˜ä¸º.jpgæ–‡ä»¶
                img_rgb.save(new_file_path)

            print(f"Converted {filename} to {new_filename}")

def init_chrome_and_login(creator_url, cookie_path, domain):
    """
    åˆå§‹åŒ– Chrome å¹¶ç™»å½•åˆ›ä½œè€…å¹³å°ï¼ˆå®Œæ•´æ³¨é‡Šç‰ˆï¼‰
    :param creator_url: åˆ›ä½œè€…ä¸­å¿ƒé¦–é¡µ URLï¼ˆå¦‚å°çº¢ä¹¦æˆ–æŠ–éŸ³ï¼‰
    :param cookie_path: Cookie æ–‡ä»¶è·¯å¾„
    :param domain: Cookie çš„ domainï¼ˆå¦‚ ".xiaohongshu.com" æˆ– "creator.douyin.com"ï¼‰
    :return: å·²ç™»å½•çš„ driver å¯¹è±¡
    """
    # å®šä¹‰chromeå±æ€§ï¼ˆä¿ç•™åŸå§‹æ³¨é‡Šï¼‰
    prefs = {
        'profile.default_content_setting_values': {
            'notifications': 2  # éšè—chromedriverçš„é€šçŸ¥
        },
        'credentials_enable_service': False,  # ç¦ç”¨å‡­æ®ç®¡ç†æœåŠ¡
        'profile.password_manager_enabled': False  # éšè—chromedriverè‡ªå¸¦çš„ä¿å­˜å¯†ç åŠŸèƒ½
    }

    # åˆ›å»ºä¸€ä¸ªé…ç½®å¯¹è±¡ï¼ˆä¿ç•™åŸå§‹æ³¨é‡Šï¼‰
    options = webdriver.ChromeOptions()
    options.add_experimental_option('prefs', prefs)
    options.add_experimental_option('excludeSwitches', ['enable-automation'])  # è®¾ç½®ä¸ºå¼€å‘è€…æ¨¡å¼
    options.add_argument('--disable-gpu')  # è°·æ­Œæ–‡æ¡£æåˆ°éœ€è¦åŠ ä¸Šè¿™ä¸ªå±æ€§æ¥è§„é¿bug

    # æ‰“å¼€çª—å£ï¼ˆä¿ç•™åŸå§‹æ³¨é‡Šï¼‰
    driver = webdriver.Chrome(options=options)
    driver.maximize_window()
    driver.implicitly_wait(5)

    # è®¿é—®åˆ›ä½œè€…ä¸­å¿ƒï¼ˆä¿ç•™åŸå§‹æ³¨é‡Šï¼‰
    driver.get(url=creator_url)
    time.sleep(4)
    driver.delete_all_cookies()

    # æŒä¹…åŒ–ç™»å½•ï¼ˆä¿ç•™åŸå§‹æ³¨é‡Šå’Œå¼‚å¸¸å¤„ç†ï¼‰
    login = CookieLogin(cookie_path)
    cookies = login.load_cookies()
    try:
        for cookie in cookies:
            cookie_dict = {
                'domain': domain,
                'name': cookie.get('name'),
                'value': cookie.get('value'),
                "expires": '',
                'path': '/',
                'httpOnly': False,
                'HostOnly': False,
                'Secure': False
            }
            print(cookie_dict)  # ä¿ç•™åŸå§‹è°ƒè¯•è¾“å‡º
            driver.add_cookie(cookie_dict)
    except Exception as e:
        print(e)  # ä¿ç•™åŸå§‹å¼‚å¸¸æ‰“å°

    time.sleep(5)
    driver.refresh()  # ä¿ç•™åŸå§‹åˆ·æ–°é€»è¾‘
    time.sleep(5)
    return driver

def xhs_video_upload(video_path, cover_path, your_title, your_desc, cookie_path):
    # åˆå§‹åŒ– Chrome å¹¶ç™»å½•ï¼ˆå¸¦å®Œæ•´æ³¨é‡Šï¼‰
    driver = init_chrome_and_login(
        creator_url="https://creator.xiaohongshu.com",
        cookie_path=cookie_path,
        domain=".xiaohongshu.com"  # å°çº¢ä¹¦éœ€è¦å­åŸŸå
    )

    time.sleep(5)
    url = "https://creator.xiaohongshu.com/publish/publish"
    driver.get(url)

    time.sleep(2)
    
    # è§†é¢‘ä¸Šä¼ 
    video_upload = driver.find_element(By.CSS_SELECTOR, 'input[type="file"]')
    video_upload.send_keys(video_path)
    # ç­‰å¾…è§†é¢‘ä¸Šä¼ å®Œæˆ
    print("è§†é¢‘ä¸Šä¼ å®Œæˆï¼")
    time.sleep(2)

    # ç‚¹å‡»è®¾ç½®å°é¢
    set_cover = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.XPATH, '//div[contains(@class, "text") and contains(text(), "è®¾ç½®å°é¢")]'))
    )
    set_cover.click()
    time.sleep(5)
    
    # å°é¢ä¸Šä¼ 
    cover_uplaod = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, 'input[type="file"][accept*="image"]'))
    )
    driver.execute_script("arguments[0].style.display = 'block';", cover_uplaod)
    cover_uplaod.send_keys(cover_path)
    print("å°é¢ä¸Šä¼ å®Œæˆï¼")
    time.sleep(5)

    confirm_btn = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.XPATH, '//*[@id="mojito-btn-container"]/button[2]'))
    )
    confirm_btn.click()
    print("å°é¢è®¾ç½®å®Œæˆï¼")
    time.sleep(2)
    
    # è¾“å…¥æ ‡é¢˜å’Œæè¿°
    title_input = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, "input.d-text[placeholder='å¡«å†™æ ‡é¢˜ä¼šæœ‰æ›´å¤šèµå“¦ï½']"))
    )
    driver.execute_script("arguments[0].focus();", title_input)  # å¼ºåˆ¶èšç„¦
    title_input.clear()
    title_input.send_keys(your_title)
    print("æ ‡é¢˜å·²å¡«å†™ï¼")

    desc_input = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, "div.ql-editor.ql-blank[contenteditable='true']"))
    )
    desc_input.clear()
    desc_input.send_keys(your_desc)
    print("æè¿°å·²å¡«å†™ï¼")
    time.sleep(2)
    
    # ç‚¹å‡»å‘å¸ƒ
    driver.find_element(By.XPATH, '//*[@id="publish-container"]/div[2]/div[2]/div/button[1]/div/span').click()
    print("è§†é¢‘å‘å¸ƒæˆåŠŸï¼")
    time.sleep(10)
    driver.close()
    driver.quit()

def dy_video_upload(video_path, cover_path, your_title, your_desc, cookie_path):
    # åˆå§‹åŒ– Chrome å¹¶ç™»å½•ï¼ˆå¸¦å®Œæ•´æ³¨é‡Šï¼‰
    driver = init_chrome_and_login(
        creator_url="https://creator.douyin.com",
        cookie_path=cookie_path,
        domain="creator.douyin.com"  # æŠ–éŸ³åªéœ€ä¸»åŸŸå
    )
    time.sleep(5)
    url = "https://creator.douyin.com/creator-micro/content/upload"
    driver.get(url)

    time.sleep(2)
    print("åˆ·æ–°æˆåŠŸ")

    # è§†é¢‘ä¸Šä¼ 
    video_upload = driver.find_element(By.XPATH, '//input[@type="file" and contains(@accept, "video/") and @style="display: none;"]')
    video_upload.send_keys(video_path)
    # ç­‰å¾…è§†é¢‘ä¸Šä¼ å®Œæˆ
    print("è§†é¢‘ä¸Šä¼ å®Œæˆï¼")
    time.sleep(10)

    # ç‚¹å‡»è®¾ç½®å°é¢
    set_cover = WebDriverWait(driver, 15).until(
        EC.element_to_be_clickable((By.XPATH, '//div[contains(@class, "filter-")]//div[text()="é€‰æ‹©å°é¢"]'))
    )
    set_cover.click()
    time.sleep(5)

    # å°é¢ä¸Šä¼ 
    cover_uplaod = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR,  'input.semi-upload-hidden-input[type="file"]'))
    )
    driver.execute_script("arguments[0].style.display = 'block';", cover_uplaod)
    cover_uplaod.send_keys(cover_path)
    print("å°é¢ä¸Šä¼ å®Œæˆï¼")
    time.sleep(5)

    confirm_btn = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.XPATH, '//button[contains(@class, "semi-button-primary")]/span[text()="å®Œæˆ"]/..'))
    )
    confirm_btn.click()
    print("å°é¢è®¾ç½®å®Œæˆï¼")
    time.sleep(2)
    
    # è¾“å…¥æ ‡é¢˜å’Œæè¿°
    title_input = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.XPATH, '//input[contains(@class, "semi-input") and @placeholder="å¡«å†™ä½œå“æ ‡é¢˜ï¼Œä¸ºä½œå“è·å¾—æ›´å¤šæµé‡"]'))
    )
    driver.execute_script("arguments[0].focus();", title_input)  # å¼ºåˆ¶èšç„¦
    title_input.clear()
    title_input.send_keys(your_title)
    print("æ ‡é¢˜å·²å¡«å†™ï¼")

    desc_input = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, 'div.editor-kit-container[data-placeholder="æ·»åŠ ä½œå“ç®€ä»‹"]'))
    )
    desc_input.clear()
    desc_input.send_keys(your_desc)
    print("æè¿°å·²å¡«å†™ï¼")
    time.sleep(2)
    
    # ç‚¹å‡»å‘å¸ƒ
    driver.find_element(By.XPATH, '//button[contains(@class, "primary-") and text()="å‘å¸ƒ"]').click()

    print("è§†é¢‘å‘å¸ƒæˆåŠŸï¼")
    time.sleep(10)
    driver.close()
    driver.quit()

def sph_video_upload(video_path, cover_path, your_title, your_desc, cookie_path):
    # åˆå§‹åŒ– Chrome å¹¶ç™»å½•å¾®ä¿¡è§†é¢‘å·å¹³å°ï¼ˆä¿ç•™å…¨éƒ¨åŸå§‹æ³¨é‡Šï¼‰
    driver = init_chrome_and_login(
        creator_url="https://channels.weixin.qq.com",
        cookie_path=cookie_path,
        domain="channels.weixin.qq.com"  # å¾®ä¿¡è§†é¢‘å·ä¸“ç”¨domain
    )

    time.sleep(5)
    url = "https://channels.weixin.qq.com/platform"
    # url = "https://channels.weixin.qq.com/platform/post/create"
    driver.get(url)

    time.sleep(2)
    print("åˆ·æ–°æˆåŠŸ")

    # è§†é¢‘ä¸Šä¼ 
    # video_upload = driver.find_element(By.XPATH, '//input[@type="file" and @accept="video/mp4,video/x-m4v,video/*"]')
    video_upload = driver.find_element(By.CSS_SELECTOR, "input[type='file']")
    video_upload.send_keys(video_path)
    # ç­‰å¾…è§†é¢‘ä¸Šä¼ å®Œæˆ
    print("è§†é¢‘ä¸Šä¼ å®Œæˆï¼")
    time.sleep(10)

    # ç‚¹å‡»è®¾ç½®å°é¢
    set_cover = WebDriverWait(driver, 15).until(
        EC.element_to_be_clickable((By.XPATH, '//div[contains(@class, "filter-")]//div[text()="é€‰æ‹©å°é¢"]'))
    )
    set_cover.click()
    time.sleep(5)

    # å°é¢ä¸Šä¼ 
    cover_uplaod = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR,  'input.semi-upload-hidden-input[type="file"]'))
    )
    driver.execute_script("arguments[0].style.display = 'block';", cover_uplaod)
    cover_uplaod.send_keys(cover_path)
    print("å°é¢ä¸Šä¼ å®Œæˆï¼")
    time.sleep(5)

    confirm_btn = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.XPATH, '//button[contains(@class, "semi-button-primary")]/span[text()="å®Œæˆ"]/..'))
    )
    confirm_btn.click()
    print("å°é¢è®¾ç½®å®Œæˆï¼")
    time.sleep(2)
    
    # è¾“å…¥æ ‡é¢˜å’Œæè¿°
    title_input = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.XPATH, '//input[contains(@class, "semi-input") and @placeholder="å¡«å†™ä½œå“æ ‡é¢˜ï¼Œä¸ºä½œå“è·å¾—æ›´å¤šæµé‡"]'))
    )
    driver.execute_script("arguments[0].focus();", title_input)  # å¼ºåˆ¶èšç„¦
    title_input.clear()
    title_input.send_keys(your_title)
    print("æ ‡é¢˜å·²å¡«å†™ï¼")

    desc_input = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, 'div.editor-kit-container[data-placeholder="æ·»åŠ ä½œå“ç®€ä»‹"]'))
    )
    desc_input.clear()
    desc_input.send_keys(your_desc)
    print("æè¿°å·²å¡«å†™ï¼")
    time.sleep(2)
    
    # ç‚¹å‡»å‘å¸ƒ
    driver.find_element(By.XPATH, '//button[contains(@class, "primary-") and text()="å‘å¸ƒ"]').click()

    print("è§†é¢‘å‘å¸ƒæˆåŠŸï¼")
    time.sleep(10)
    driver.close()
    driver.quit()

def main():
    # è¾“å‡ºç›®å½•
    pass

if __name__ == "__main__":
    main()