# freepublishæ¥å£ä¸æ˜¯ç¾¤å‘æ¥å£ï¼Œä¸èƒ½ç›´æ¥ä½¿ç”¨
import os
import re
import json
import time
import requests
from typing import Dict, List, Optional, Tuple
from urllib.parse import unquote
from .video_core import markdown_to_html
from config import Config

class WeChatPublisher:
    def __init__(self, app_id: str, app_secret: str, article_name: str = "demo", source_url: str = ""):
        self.app_id = app_id
        self.app_secret = app_secret
        self.source_url = source_url  # å­˜å‚¨ä¸»ç¨‹åºä¼ å…¥çš„é“¾æ¥
        self.access_token = None
        self.token_expire_time = 0
        # ä½¿ç”¨é…ç½®ä¸­çš„æ–‡ç« ç›®å½•
        self.article_dir = os.path.join(Config.ARTICLE_DIR, article_name)
        self.md_filename = f"{article_name}.md"  # é…å¥—çš„markdownæ–‡ä»¶å
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.article_dir, exist_ok=True)
        
        # å›¾ç‰‡æ‰©å±•åç™½åå•
        self.ALLOWED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}

    def get_access_token(self) -> str:
        """è·å–å¾®ä¿¡access_tokenï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼‰"""
        if self.access_token and time.time() < self.token_expire_time:
            return self.access_token

        url = f"https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&appid={self.app_id}&secret={self.app_secret}"
        response = requests.get(url)
        data = response.json()

        if 'access_token' in data:
            self.access_token = data['access_token']
            self.token_expire_time = time.time() + data['expires_in'] - 300
            return self.access_token
        raise Exception(f"è·å–access_tokenå¤±è´¥: {data}")

    def _validate_image(self, image_path: str):
        """éªŒè¯å›¾ç‰‡æ˜¯å¦ç¬¦åˆè¦æ±‚"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
            
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆâ‰¤10MBï¼‰
        MAX_SIZE = 10 * 1024 * 1024
        if os.path.getsize(image_path) > MAX_SIZE:
            raise ValueError(f"å›¾ç‰‡å¤§å°è¶…è¿‡10MBé™åˆ¶: {image_path}")
            
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        ext = os.path.splitext(image_path)[1].lower()
        if ext not in self.ALLOWED_EXTENSIONS:
            raise ValueError(f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ {ext}")

    def upload_image(self, image_name: str) -> Tuple[str, str]:
        """
        ä¸Šä¼ å›¾ç‰‡åˆ°å¾®ä¿¡æ°¸ä¹…ç´ æåº“
        è¿”å›ï¼š(media_id, image_url)
        æ³¨ï¼šimage_url ç›´æ¥ä»å¾®ä¿¡APIè¿”å›çš„jsonä¸­è·å–ï¼Œç¡®ä¿æœ‰æ•ˆæ€§
        """
        image_path = os.path.join(self.article_dir, image_name)
        self._validate_image(image_path)
        
        token = self.get_access_token()
        url = f"https://api.weixin.qq.com/cgi-bin/material/add_material?access_token={token}&type=image"

        for attempt in range(3):
            try:
                with open(image_path, 'rb') as f:
                    response = requests.post(url, files={'media': f}, timeout=10)
                    data = response.json()

                if 'media_id' in data and 'url' in data:  # å…³é”®ä¿®æ”¹ï¼šç›´æ¥ä½¿ç”¨APIè¿”å›çš„url
                    print(f"âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸ: {image_name} -> {data['media_id']}")
                    return data['media_id'], data['url']  # ä¸å†æ‰‹åŠ¨æ‹¼æ¥URL
                raise Exception(f"å¾®ä¿¡APIè¿”å›æ•°æ®ä¸å®Œæ•´: {data}")
            except Exception as e:
                if attempt == 2:
                    raise Exception(f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼ˆé‡è¯•{attempt+1}æ¬¡ï¼‰: {str(e)}")
                time.sleep(1)

    def process_images(self, md_content: str) -> Tuple[str, Dict[str, Tuple[str, str]]]:
        """
        å¤„ç†æ‰€æœ‰å›¾ç‰‡å¹¶è¿”å›ï¼š
        - å¤„ç†åçš„markdownå†…å®¹
        - å›¾ç‰‡æ˜ å°„è¡¨ {åŸæ–‡ä»¶å: (media_id, url)}
        """
        img_map = {}
        
        # åŸºç¡€ç‰ˆæ­£åˆ™åŒ¹é…
        pattern = r'\((.*?)\)'  # æ­£åˆ™è¡¨è¾¾å¼
        matches = re.findall(pattern, md_content)  # ä½¿ç”¨ findall è€Œä¸æ˜¯ search
        image_refs = list(set(matches))  # å»é‡å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
        print(f"å‘ç° {len(image_refs)} ä¸ªå›¾ç‰‡å¼•ç”¨: {list(image_refs)}")

        # ä¸Šä¼ æ‰€æœ‰å›¾ç‰‡
        for img_ref in image_refs:
            # ç›´æ¥ä½¿ç”¨æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
            img_name = os.path.basename(unquote(img_ref.strip()))
            try:
                media_id, image_url = self.upload_image(img_name)
                img_map[img_ref] = (media_id, image_url)
            except Exception as e:
                raise Exception(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {img_name}\n{str(e)}")

        # æ›¿æ¢å†…å®¹ä¸­çš„å›¾ç‰‡é“¾æ¥
        for img_ref, (_, image_url) in img_map.items():
            md_content = md_content.replace(f'({img_ref})', f'({image_url})')
            print(f'({image_url})')

        return md_content, img_map

    def parse_markdown(self) -> Dict:
        """è§£æMarkdownæ–‡ä»¶ï¼ˆé›†æˆYAMLå…ƒæ•°æ®ã€å›¾ç‰‡å¤„ç†å’ŒHTMLè½¬æ¢ï¼‰"""
        md_file_path = os.path.join(self.article_dir, self.md_filename)
        if not os.path.exists(md_file_path):
            raise FileNotFoundError(f"Markdownæ–‡ä»¶ä¸å­˜åœ¨: {md_file_path}")

        with open(md_file_path, 'r', encoding='utf-8') as f:
            md_content = f.read()

        # å¤„ç†å›¾ç‰‡ï¼ˆå¼ºåˆ¶æ‰€æœ‰å›¾ç‰‡å¿…é¡»å…ˆä¸Šä¼ ï¼‰
        processed_content, img_map = self.process_images(md_content)  # æ³¨æ„ï¼šæ­¤å¤„ç”¨åŸå§‹ md_content ç¡®ä¿å›¾ç‰‡è§£ææ­£ç¡®

        # è°ƒç”¨ markdown_to_html ç»Ÿä¸€å¤„ç† YAML å’Œ HTML è½¬æ¢
        html_content, metadata = markdown_to_html(processed_content)

        # è‡ªåŠ¨é€‰æ‹©å°é¢å›¾ï¼ˆä¼˜å…ˆé€‰æ‹©æ–‡ä»¶åå« cover/å°é¢çš„å›¾ç‰‡ï¼‰
        thumb_media_id = None
        for img_ref, (media_id, _) in img_map.items():
            if re.search(r'cover|å°é¢|thumb', img_ref, re.IGNORECASE):
                thumb_media_id = media_id
                break
        # å¦‚æœæ²¡æœ‰æ˜ç¡®å°é¢ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡
        if not thumb_media_id and img_map:
            thumb_media_id = next(iter(img_map.values()))[0]

        # æå–æ ‡é¢˜ï¼ˆä¼˜å…ˆä½¿ç”¨ YAML ä¸­çš„ titleï¼Œå¦åˆ™ä» Markdown çš„ # æ ‡é¢˜æå–ï¼‰
        title = metadata.get('title')  # å…ˆå°è¯•ä» YAML è·å–
        if not title:
            title_match = re.search(r'^#+\s+(.+)$', md_content, re.MULTILINE)
            title = title_match.group(1).strip() if title_match else "æœªå‘½åæ–‡ç« "

        # æå–æ‘˜è¦ï¼ˆä¼˜å…ˆä½¿ç”¨ YAML ä¸­çš„ digestï¼Œå¦åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰
        digest = metadata.get('digest')
        if not digest:
            plain_text = re.sub(r'[#*`\-!$$$$]', '', md_content)  # ç§»é™¤Markdownæ ‡è®°
            digest = ' '.join(plain_text.split())[:140]  # æˆªå–å‰140å­—ç¬¦

        print(f"âœ… è§£æå®Œæˆ: {title}")
        print(f"æ‘˜è¦: {digest}")
        print(f"å°é¢å›¾Media ID: {thumb_media_id}")
        print(f"å›¾ç‰‡æ•°é‡: {len(img_map)}")

        return {
            'title': title,
            'content': html_content,
            'digest': digest,
            'thumb_media_id': thumb_media_id,
            'image_map': img_map,
            'metadata': metadata  # è¿”å›å®Œæ•´çš„YAMLå…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
        }
    def publish(self) -> bool:
        """å‘å¸ƒæ–‡ç« åˆ°å¾®ä¿¡å…¬ä¼—å·ï¼ˆç›´æ¥å‘å¸ƒï¼Œéè‰ç¨¿ï¼‰"""
        print("\n" + "="*50)
        print("ğŸ“ å¼€å§‹å‘å¸ƒæµç¨‹")
        
        try:
            # 1. è§£æMarkdownï¼ˆåŒ…å«å›¾ç‰‡ä¸Šä¼ ï¼‰
            article = self.parse_markdown()
            
            # 2. éªŒè¯å…³é”®æ•°æ®
            if not article["content"]:
                raise ValueError("é”™è¯¯ï¼šæ–‡ç« å†…å®¹ä¸ºç©º")
            if not article["thumb_media_id"]:
                raise ValueError("é”™è¯¯ï¼šæœªè®¾ç½®å°é¢å›¾")
            # è¯»å–HTMLæ–‡ä»¶,å¹¶æ·»åŠ åˆ°æ–‡ç« å†…å®¹æœ«å°¾
            footer_path = os.path.join("main", "static", "html", "seo_footer_wx.html")
            with open(footer_path, "r", encoding="utf-8") as f:
                SEO_FOOTER = f.read()
            article['content'] = article['content'] + SEO_FOOTER

            # 3. å‡†å¤‡å‘å¸ƒæ•°æ®
            payload = {
                "articles": [
                    {
                        "title": article['title'],
                        "thumb_media_id": article['thumb_media_id'],
                        "author": "è§‚æµ·",
                        "digest": article['digest'],
                        "show_cover_pic": 1,
                        "content": article['content'],
                        "content_source_url": self.source_url,
                        "open_comment": 1,
                        "only_fans_can_comment": 0
                    }
                ]
            }

            # 4. å…ˆæ·»åŠ åˆ°è‰ç¨¿ç®±ï¼ˆè·å–media_idï¼‰
            token = self.get_access_token()
            draft_url = f"https://api.weixin.qq.com/cgi-bin/draft/add?access_token={token}"
            
            draft_response = requests.post(
                draft_url,
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                headers={'Content-Type': 'application/json'} 
            )
            
            draft_result = draft_response.json()
            
            
            media_id = draft_result.get('media_id')
            print(f"âœ… è‰ç¨¿åˆ›å»ºæˆåŠŸï¼Œè·å–åˆ°media_id: {media_id}")

            # 5. ç›´æ¥å‘å¸ƒæ–‡ç« 
            publish_url = f"https://api.weixin.qq.com/cgi-bin/freepublish/submit?access_token={token}"
            publish_payload = {
                "media_id": media_id
            }
            
            publish_response = requests.post(
                publish_url,
                data=json.dumps(publish_payload, ensure_ascii=False).encode('utf-8'),
                headers={'Content-Type': 'application/json'} 
            )
            
            publish_result = publish_response.json()
            
            # æ‰“å°å®Œæ•´çš„å“åº”ç»“æœç”¨äºè°ƒè¯•
            print("\nå¾®ä¿¡APIå‘å¸ƒå“åº”ç»“æœ:")
            print(json.dumps(publish_result, indent=2, ensure_ascii=False))
            
            if publish_result.get('errcode') == 0:
                print(f"\nâœ… å‘å¸ƒæˆåŠŸï¼æ–‡ç« å·²å‘å¸ƒ")
                print(f"å‘å¸ƒä»»åŠ¡ID: {publish_result.get('publish_id')}")
                print(f"æ–‡ç« media_id: {media_id}")
                print(f"å°é¢å›¾Media ID: {article['thumb_media_id']}")
                print("æ‰€æœ‰å›¾ç‰‡ä¸Šä¼ ç»“æœ:")
                for img_ref, (media_id, url) in article['image_map'].items():
                    print(f"- {img_ref}: {media_id}")
                return True
            print(publish_result)
            # é”™è¯¯å¤„ç†ï¼ˆä¿æŒä¸å˜ï¼‰
            error_code = publish_result.get('errcode', 'æœªçŸ¥')
            error_msg = publish_result.get('errmsg', 'æœªçŸ¥é”™è¯¯')
            
            error_explanations = {
                40001: "æ— æ•ˆçš„access_tokenï¼Œè¯·æ£€æŸ¥appidå’Œappsecretæ˜¯å¦æ­£ç¡®",
                40002: "ä¸åˆæ³•çš„å‡­è¯ç±»å‹",
                40007: "ä¸åˆæ³•çš„media_idï¼Œå¯èƒ½æ˜¯å›¾ç‰‡ä¸Šä¼ å¤±è´¥",
                41001: "ç¼ºå°‘å¿…è¦å‚æ•°",
                45009: "æ¥å£è°ƒç”¨è¶…è¿‡é™åˆ¶",
                48001: "APIåŠŸèƒ½æœªæˆæƒï¼Œè¯·æ£€æŸ¥å…¬ä¼—å·æƒé™è®¾ç½®",
                88000: "æ²¡æœ‰ç•™è¨€æƒé™",
                88001: "è¯¥å›¾æ–‡ä¸å­˜åœ¨",
                88002: "æ–‡ç« çŠ¶æ€é”™è¯¯",
            }
            
            explanation = error_explanations.get(error_code, 
                "è¯·å‚è€ƒå¾®ä¿¡å…¬ä¼—å¹³å°å¼€å‘æ–‡æ¡£æŸ¥çœ‹é”™è¯¯ä»£ç å«ä¹‰")
            
            error_details = (
                f"å‘å¸ƒå¤±è´¥ï¼\n"
                f"é”™è¯¯ä»£ç : {error_code}\n"
                f"é”™è¯¯ä¿¡æ¯: {error_msg}\n"
                f"å¯èƒ½åŸå› : {explanation}\n"
                f"è¯·æ±‚æ•°æ®: {json.dumps(payload, indent=2, ensure_ascii=False)}"
            )
            
            raise Exception(error_details)

        except requests.exceptions.RequestException as e:
            raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
        except json.JSONDecodeError as e:
            raise Exception(f"è§£æå¾®ä¿¡APIå“åº”å¤±è´¥: {str(e)}")
        except Exception as e:
            raise Exception(f"å‘å¸ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")